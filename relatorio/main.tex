%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

\documentclass[conference]{IEEEtran}

% *** GRAPHICS RELATED PACKAGES ***
\usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
% \graphicspath{{../pdf/}{../jpeg/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
% \DeclareGraphicsExtensions{.pdf,.jpeg,.png}

% *** MATH PACKAGES ***
\usepackage{amsmath}

% *** PDF, URL AND HYPERLINK PACKAGES ***
\usepackage{url}

% A codificação deste documento está em UTF-8.
\usepackage[utf8]{inputenc}
% Hifenização do texto e tradução de palavras como Abstract, Section, etc.
\usepackage[brazil]{babel}
% Hifenização de palavras acentuadas.
\usepackage[T1]{fontenc}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{Utilizando Spatial Transformer Networks}


\author{\IEEEauthorblockN{Lucas Caetano Possatti}
\IEEEauthorblockA{Universidade Federal do Espírito Santo\\
Email: lucas.cpossatti@gmail.com}
\and
\IEEEauthorblockN{Rafael Horimoto de Freistas}
\IEEEauthorblockA{Universidade Federal do Espírito Santo\\
Email: rafael.hdefreitas@gmail.com}}

% make the title area
\maketitle

\begin{abstract}
Redes Neurais Convolucionais (CNNs) estão sendo muito utilizadas para alcançar resultados do estado da arte na área de Visão Computacional. Uma propriedade desejável para tais modelos, que lidam com imagens, é serem capazes de desassociar posicionamento e deformações de objetos e de características da imagem. Assim sendo, tais modelos podem se tornar invariantes espacialmente ou até mesmo usarem a informação desassociada para ajudar na tarefa de inferência.
Para alcansar tal propriedade, é explorado nesse trabalho, baseado no trabalho de Jaderberg et al \cite{jaderberg2015spatial}, o uso de \textit{Spatial Transformer Networks} (STNs). STNs são módulos que podem ser incluídos em outras redes neurais, provendo capacidades de transformação espacial, e podem ser usados juntamente com o algoritmo de backpropagation.
\end{abstract}


% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introdução}

Redes Neurais Convolucionais (CNNs) estão sendo muito utilizadas para alcançar resultados do estado da arte na área de Visão Computacional. Uma propriedade desejável para tais modelos, que lidam com imagens, é serem capazes de desassociar posicionamento e deformações de objetos e de características da imagem. Assim sendo, tais modelos podem se tornar invariantes espacialmente ou até mesmo usarem a informação desassociada para ajudar na tarefa de inferência.
Certa invariância espacial pode ser obtida através de camadas de \textit{max-pooling} local. Porém, devido ao tipicamente pequeno espaço no qual o \textit{max-pooling} atua, tal invariância só é alcansada após um profunda hierarquia de convoluções e camadas de \textit{max-pooling}, de forma que as camadas intermediárias não são invariantes a largas transformações nos dados de entrada.
Para alcansar tal propriedade, é explorado nesse trabalho, baseado no trabalho de Jaderberg et al \cite{jaderberg2015spatial}, o uso de \textit{Spatial Transformer Networks} (STNs). STNs são módulos que podem ser incluídos em outras redes neurais, provendo capacidades de transformação espacial, e podem ser usados juntamente com o algoritmo de backpropagation. A STN pode ter como entrada uma imagem ou um mapa de características, inferi uma transformação condicionada a entrada e aplica a transformação na entrada para obter a saída.
A STN é dividida em três partes: rede de localização, gerador de malha e amostrador. A rede de localização aprende os parâmetros de uma transformação condicionados à entrada da STN. O gerador de malha então usa os parâmetros aprendidos pela rede de localização para transformar a malha de pixels da saída. A malha de pixels transformada defini as coordenadas correspondentes na entrada, porém tais coordenadas podem não ser inteiras, o que impossibilita definir diretamente cada pixel de saída em função de um único pixel de entrada. Para tratar tal problema, o amostrador usa as coordenadas da malha transformada juntamente com os pixels de entrada e aplica um algoritmo de mapeamento de textura para gerar os pixels de saída.

\section{Trabalhos Correlatos}

Segundo Jaderberg et al. \cite{jaderberg2015spatial}, trabalhos anteriores modelam transformações com redes neurais \cite{hinton1981parallel,hinton2011transforming,tieleman2014optimizing}, aprendem e analisam representações invariantes a transformações \cite{bruna2013invariant,cohen2014transformation,gens2014deep,kanazawa2014locally,lenc2015understanding,sohn2012learning} e usam mecanismos de atenção e detecção para seleção de características \cite{ba2014multiple,erhan2014scalable,girshick2014rich,gregor2015draw,schmidhuber1991learning,sermanet2014attention}.
Trabalho anterior por Hinton \cite{hinton1981parallel} visava atribuir frames canônicos de referência para partes de objetos, um tema que repercurtiu em \cite{hinton2011transforming} onde transformações afins 2D foram modeladas para criar um modelo generativo composto de partes transformadas. Os alvos do esquema de treino generativo são as imagens de entrada transformadas, com as transformações entre imagens de entrada e alvos dadas como entrada adicional para a rede. O resultado é um modelo generativo que consegue aprender a gerar imagens transformadas de objetos compondo partes. A noção de composição de partes transformadas é levada a frente por Tieleman \cite{tieleman2014optimizing}, onde partes aprendidas são explicitamente transformadas por transformações afins, com a transformação inferida pela rede. Tais modelos generativos são capazes de aprender características discriminativas para classificação com supervisão de transformações.
A invariância e equivariância de representações de CNNs em relação a transformações de imagens de entrada são estudadas em \cite{lenc2015understanding} estimando as relações lineares entre representações das imagens originais e transformadas. Cohen & Welling \cite{cohen2014transformation} analizam esse comportamento em relação a grupos simétricos, que também é explorado na arquitetura proposta por Gens & Domingos \cite{gens2014deep}, resultando em mapas de características que são mais invariantes a grupos simétricos. Outras tentativas de criar representações invariantes a transformações são \textit{scattering networks} \cite{bruna2013invariant}, e CNNs que constroem bancos de filtros com filtros transformados \cite{kanazawa2014locally,sohn2012learning}.
Stollenga et al. \cite{stollenga2014deep} usa uma política baseada em ativações de uma rede para reunir as respostas dos filtros da rede para uma subsequente passagem da mesma imagem e então permitir atenção para características específicas. Nesse trabalho, é focado alcansar representações invariantes manipulando os dados em vez dos extratores de características, algo que foi feito para agrupamento em \cite{frey2002fast}.
Redes neurais com atenção seletiva manipulam os dados fazendo recortes, e então são capazes de aprender invariância a translação. Trabalhos como \cite{ba2014multiple,sermanet2014attention} são treinados com aprendizado de reforço para evitar a necessidade de um mecanismo de atenção diferenciável, enquanto [14] usa um mecanismo de atenção diferenciável usando kernels gaussianos em um modelo generativo. O trabalho por Girshick et al. \cite{girshick2014rich} usa um algoritmo de proposição de região como uma forma de atenção, e \cite{erhan2014scalable} mostra que é possível fazer regressão de regiões salientes com uma CNN. O modelo apresentado nesse trabalho pode ser visto como uma generalização de atenção diferenciável para qualquer transformação espacial.

\section{Metodologia}


\section{Experimentos}


\section{Resultados}


% conference papers do not normally have an appendix

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

% \begin{thebibliography}{1}

% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

% \end{thebibliography}

\bibliography{bibliography}
\bibliographystyle{ieeetr}

\end{document}


